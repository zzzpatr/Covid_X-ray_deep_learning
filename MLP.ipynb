{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "meaning-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from IPython.display import display\n",
    "from IPython.display import Image as _Imgdis\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from tensorflow.image import resize\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout, Activation\n",
    "import keras.backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import optimizers\n",
    "import sys\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import *\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "conventional-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_train_DG = pd.read_csv('train_DG.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "gentle-prescription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 65536)\n",
      "(251,)\n",
      "(333, 65536)\n",
      "(333,)\n",
      "(66, 65536)\n",
      "(66,)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.iloc[: , 1:-1]\n",
    "y_train = df_train.iloc[: , -1:].values.ravel()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_train_DG = df_train_DG.iloc[: , 1:-1]\n",
    "y_train_DG = df_train_DG.iloc[: , -1:].values.ravel()\n",
    "print(X_train_DG.shape)\n",
    "print(y_train_DG.shape)\n",
    "\n",
    "X_test = df_test.iloc[: , 1:-1]\n",
    "y_test = df_test.iloc[: , -1:].values.ravel()\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "frequent-princess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 3)\n",
      "(333, 3)\n",
      "(66, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import *\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = to_categorical(label_encoder.fit_transform(y_train),3)\n",
    "y_train_DG = to_categorical(label_encoder.fit_transform(y_train_DG),3)\n",
    "y_test = to_categorical(label_encoder.fit_transform(y_test),3)\n",
    "print(y_train.shape)\n",
    "print(y_train_DG.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enclosed-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256,input_dim=X_train.shape[1],kernel_initializer=\"uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(128,kernel_initializer=\"uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64,kernel_initializer=\"uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "severe-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,y,test_x,test_y):\n",
    "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x,y, test_size=0.25, random_state=1) # 0.25 \n",
    "    #利用grid search調參數\n",
    "    batch_size = [32, 128]\n",
    "    epochs = [30]\n",
    "    opt = ['adam']\n",
    "    param_grid = dict(optimizer=opt,batch_size=batch_size, epochs=epochs)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "    grid_result = grid.fit(X_train, y_train,validation_data=(X_val,y_val),callbacks=[callback])\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    optimizer_best = grid_result.best_params_['optimizer']\n",
    "    batch_best = grid_result.best_params_['batch_size']\n",
    "    epochs_best = grid_result.best_params_['epochs']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    model_best =  Sequential()\n",
    "    model_best.add(Dense(256,input_dim=x.shape[1],kernel_initializer=\"uniform\"))\n",
    "    model_best.add(Activation('relu'))\n",
    "    model_best.add(Dropout(0.4))\n",
    "    model_best.add(Dense(128,kernel_initializer=\"uniform\"))\n",
    "    model_best.add(Activation('relu'))\n",
    "    model_best.add(Dropout(0.4))\n",
    "    model_best.add(Dense(64,kernel_initializer=\"uniform\"))\n",
    "    model_best.add(Activation('relu'))\n",
    "    model_best.add(Dropout(0.4))\n",
    "    model_best.add(Dense(3))\n",
    "    model_best.add(Activation('softmax'))\n",
    "    model_best.compile(optimizer=optimizer_best, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    history = model_best.fit(x, y,batch_size=batch_best,epochs=epochs_best,callbacks=[callback])\n",
    "    Y_pred = model_best.predict_generator(test_x)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    y_test_argmax = np.argmax(test_y, axis=1)\n",
    "    accuracy = accuracy_score(y_test_argmax, y_pred)\n",
    "    print('accuracy:', accuracy)\n",
    "    precision = precision_score(y_test_argmax, y_pred, average = 'macro')\n",
    "    print('precision:', precision)\n",
    "    recall = recall_score(y_test_argmax, y_pred, average = 'macro')\n",
    "    print('recall:', recall)\n",
    "    f1 = f1_score(y_test_argmax, y_pred, average = 'macro')\n",
    "    print('f1:',f1)\n",
    "    cm = confusion_matrix(y_test_argmax, y_pred)\n",
    "    print('confusion matrix')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "typical-portrait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_test_function.<locals>.test_function at 0x7f965b2bfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 38 calls to <function Model.make_test_function.<locals>.test_function at 0x7f95ca70cc10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best: 0.877778 using {'batch_size': 32, 'epochs': 30, 'optimizer': 'rmsprop'}\n",
      "0.676608 (0.130353) with: {'batch_size': 32, 'epochs': 10, 'optimizer': 'rmsprop'}\n",
      "0.851462 (0.069610) with: {'batch_size': 32, 'epochs': 10, 'optimizer': 'adam'}\n",
      "0.751170 (0.127805) with: {'batch_size': 32, 'epochs': 20, 'optimizer': 'rmsprop'}\n",
      "0.866959 (0.079102) with: {'batch_size': 32, 'epochs': 20, 'optimizer': 'adam'}\n",
      "0.877778 (0.071033) with: {'batch_size': 32, 'epochs': 30, 'optimizer': 'rmsprop'}\n",
      "0.868129 (0.097526) with: {'batch_size': 32, 'epochs': 30, 'optimizer': 'adam'}\n",
      "0.755263 (0.100493) with: {'batch_size': 128, 'epochs': 10, 'optimizer': 'rmsprop'}\n",
      "0.792982 (0.092027) with: {'batch_size': 128, 'epochs': 10, 'optimizer': 'adam'}\n",
      "0.745614 (0.166805) with: {'batch_size': 128, 'epochs': 20, 'optimizer': 'rmsprop'}\n",
      "0.851462 (0.080277) with: {'batch_size': 128, 'epochs': 20, 'optimizer': 'adam'}\n",
      "0.797661 (0.098141) with: {'batch_size': 128, 'epochs': 30, 'optimizer': 'rmsprop'}\n",
      "0.857310 (0.107512) with: {'batch_size': 128, 'epochs': 30, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 9.1141 - accuracy: 0.3904\n",
      "Epoch 2/30\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 1.8917 - accuracy: 0.4343\n",
      "Epoch 3/30\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 1.3073 - accuracy: 0.5060\n",
      "Epoch 4/30\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 0.8771 - accuracy: 0.5817\n",
      "Epoch 5/30\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 0.8767 - accuracy: 0.5538\n",
      "Epoch 6/30\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.7401 - accuracy: 0.6335\n",
      "Epoch 7/30\n",
      "8/8 [==============================] - 2s 252ms/step - loss: 0.8070 - accuracy: 0.6534\n",
      "Epoch 8/30\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.8229 - accuracy: 0.6494\n",
      "Epoch 9/30\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.6087 - accuracy: 0.7131\n",
      "Epoch 10/30\n",
      "8/8 [==============================] - 2s 198ms/step - loss: 0.5519 - accuracy: 0.7450\n",
      "Epoch 11/30\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.6848 - accuracy: 0.7570\n",
      "Epoch 12/30\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 0.5122 - accuracy: 0.8088\n",
      "Epoch 13/30\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.6601 - accuracy: 0.7331\n",
      "Epoch 14/30\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 0.5556 - accuracy: 0.7809\n",
      "Epoch 15/30\n",
      "8/8 [==============================] - 1s 171ms/step - loss: 0.4934 - accuracy: 0.8247\n",
      "Epoch 16/30\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 0.4281 - accuracy: 0.8446\n",
      "Epoch 17/30\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.5299 - accuracy: 0.8367\n",
      "Epoch 18/30\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.3504 - accuracy: 0.8606\n",
      "Epoch 19/30\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.4691 - accuracy: 0.8486\n",
      "Epoch 20/30\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.5034 - accuracy: 0.8247\n",
      "Epoch 21/30\n",
      "8/8 [==============================] - 1s 146ms/step - loss: 0.3637 - accuracy: 0.8765\n",
      "Epoch 22/30\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 0.6097 - accuracy: 0.8247\n",
      "Epoch 23/30\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 0.3622 - accuracy: 0.8884\n",
      "WARNING:tensorflow:From <ipython-input-9-8f2986f438be>:36: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "accuracy: 0.8181818181818182\n",
      "precision: 0.8412698412698413\n",
      "recall: 0.8153846153846153\n",
      "f1: 0.812124183006536\n",
      "confusion matrix\n",
      "[[22  4  0]\n",
      " [ 0 19  1]\n",
      " [ 2  5 13]]\n"
     ]
    }
   ],
   "source": [
    "predict(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pursuant-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.831500 using {'batch_size': 32, 'epochs': 20, 'optimizer': 'adam'}\n",
      "0.699000 (0.096172) with: {'batch_size': 32, 'epochs': 10, 'optimizer': 'rmsprop'}\n",
      "0.807333 (0.097454) with: {'batch_size': 32, 'epochs': 10, 'optimizer': 'adam'}\n",
      "0.798833 (0.108254) with: {'batch_size': 32, 'epochs': 20, 'optimizer': 'rmsprop'}\n",
      "0.831500 (0.092359) with: {'batch_size': 32, 'epochs': 20, 'optimizer': 'adam'}\n",
      "0.795333 (0.110677) with: {'batch_size': 32, 'epochs': 30, 'optimizer': 'rmsprop'}\n",
      "0.819000 (0.097411) with: {'batch_size': 32, 'epochs': 30, 'optimizer': 'adam'}\n",
      "0.659167 (0.098858) with: {'batch_size': 128, 'epochs': 10, 'optimizer': 'rmsprop'}\n",
      "0.783000 (0.109366) with: {'batch_size': 128, 'epochs': 10, 'optimizer': 'adam'}\n",
      "0.715333 (0.096243) with: {'batch_size': 128, 'epochs': 20, 'optimizer': 'rmsprop'}\n",
      "0.823500 (0.085850) with: {'batch_size': 128, 'epochs': 20, 'optimizer': 'adam'}\n",
      "0.803167 (0.093792) with: {'batch_size': 128, 'epochs': 30, 'optimizer': 'rmsprop'}\n",
      "0.823500 (0.114587) with: {'batch_size': 128, 'epochs': 30, 'optimizer': 'adam'}\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 2.7929 - accuracy: 0.4625\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 1s 98ms/step - loss: 1.5478 - accuracy: 0.4474\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 1s 120ms/step - loss: 1.1202 - accuracy: 0.5255\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.8964 - accuracy: 0.5886\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.7174 - accuracy: 0.6787\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.7484 - accuracy: 0.7057\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.6485 - accuracy: 0.7267\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.5838 - accuracy: 0.7477\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.6594 - accuracy: 0.7087\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.5599 - accuracy: 0.7508\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.5418 - accuracy: 0.7718\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.4911 - accuracy: 0.8078\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.5865 - accuracy: 0.7658\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.5282 - accuracy: 0.7838\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.5172 - accuracy: 0.7958\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.4695 - accuracy: 0.8318\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.5000 - accuracy: 0.8288\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.6013 - accuracy: 0.7688\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.5133 - accuracy: 0.7658\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 1s 110ms/step - loss: 0.5501 - accuracy: 0.7568\n",
      "accuracy: 0.6515151515151515\n",
      "precision: 0.6388888888888888\n",
      "recall: 0.632051282051282\n",
      "f1: 0.5845421245421245\n",
      "confusion matrix\n",
      "[[22  3  1]\n",
      " [ 0  3 17]\n",
      " [ 2  0 18]]\n"
     ]
    }
   ],
   "source": [
    "predict(X_train_DG,y_train_DG,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "empty-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of original data with PCA = 27\n",
    "pca = PCA(n_components=27)\n",
    "pca.fit(X_train)\n",
    "X_train_PCA = pca.transform(X_train)\n",
    "X_test_PCA = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "heated-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_for_PCA(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256,input_dim=X_train_PCA.shape[1],kernel_initializer=\"uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(128,kernel_initializer=\"uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64,kernel_initializer=\"uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "def predict_for_PCA(x,y,test_x,test_y):\n",
    "    model = KerasClassifier(build_fn=create_model_for_PCA, verbose=0)\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x,y, test_size=0.25, random_state=1) # 0.25 \n",
    "    #利用grid search調參數\n",
    "    batch_size = [32, 128]\n",
    "    epochs = [10,20,30]\n",
    "    opt = ['rmsprop','adam']\n",
    "    param_grid = dict(optimizer=opt,batch_size=batch_size, epochs=epochs)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "    grid_result = grid.fit(X_train, y_train,validation_data=(X_val,y_val),callbacks=[callback])\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    optimizer_best = grid_result.best_params_['optimizer']\n",
    "    batch_best = grid_result.best_params_['batch_size']\n",
    "    epochs_best = grid_result.best_params_['epochs']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    model_best =  Sequential()\n",
    "    model_best.add(Dense(256,input_dim=x.shape[1],kernel_initializer=\"uniform\"))\n",
    "    model_best.add(Activation('relu'))\n",
    "    model_best.add(Dropout(0.4))\n",
    "    model_best.add(Dense(128,kernel_initializer=\"uniform\"))\n",
    "    model_best.add(Activation('relu'))\n",
    "    model_best.add(Dropout(0.4))\n",
    "    model_best.add(Dense(64,kernel_initializer=\"uniform\"))\n",
    "    model_best.add(Activation('relu'))\n",
    "    model_best.add(Dropout(0.4))\n",
    "    model_best.add(Dense(3))\n",
    "    model_best.add(Activation('softmax'))\n",
    "    model_best.compile(optimizer=optimizer_best, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    history = model_best.fit(x, y,batch_size=batch_best,epochs=epochs_best,callbacks=[callback])\n",
    "    Y_pred = model_best.predict_generator(test_x)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    y_test_argmax = np.argmax(test_y, axis=1)\n",
    "    accuracy = accuracy_score(y_test_argmax, y_pred)\n",
    "    print('accuracy:', accuracy)\n",
    "    precision = precision_score(y_test_argmax, y_pred, average = 'macro')\n",
    "    print('precision:', precision)\n",
    "    recall = recall_score(y_test_argmax, y_pred, average = 'macro')\n",
    "    print('recall:', recall)\n",
    "    f1 = f1_score(y_test_argmax, y_pred, average = 'macro')\n",
    "    print('f1:',f1)\n",
    "    cm = confusion_matrix(y_test_argmax, y_pred)\n",
    "    print('confusion matrix')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "small-registration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.925731 using {'batch_size': 128, 'epochs': 30, 'optimizer': 'rmsprop'}\n",
      "0.904678 (0.080949) with: {'batch_size': 32, 'epochs': 10, 'optimizer': 'rmsprop'}\n",
      "0.920468 (0.063643) with: {'batch_size': 32, 'epochs': 10, 'optimizer': 'adam'}\n",
      "0.909942 (0.066943) with: {'batch_size': 32, 'epochs': 20, 'optimizer': 'rmsprop'}\n",
      "0.915205 (0.078947) with: {'batch_size': 32, 'epochs': 20, 'optimizer': 'adam'}\n",
      "0.915205 (0.071587) with: {'batch_size': 32, 'epochs': 30, 'optimizer': 'rmsprop'}\n",
      "0.920468 (0.079162) with: {'batch_size': 32, 'epochs': 30, 'optimizer': 'adam'}\n",
      "0.904678 (0.080949) with: {'batch_size': 128, 'epochs': 10, 'optimizer': 'rmsprop'}\n",
      "0.899708 (0.092372) with: {'batch_size': 128, 'epochs': 10, 'optimizer': 'adam'}\n",
      "0.909942 (0.070961) with: {'batch_size': 128, 'epochs': 20, 'optimizer': 'rmsprop'}\n",
      "0.909942 (0.078380) with: {'batch_size': 128, 'epochs': 20, 'optimizer': 'adam'}\n",
      "0.925731 (0.067697) with: {'batch_size': 128, 'epochs': 30, 'optimizer': 'rmsprop'}\n",
      "0.925731 (0.067697) with: {'batch_size': 128, 'epochs': 30, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0457 - accuracy: 0.4502\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.8088\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.8566\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8486\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2587 - accuracy: 0.8964\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2095 - accuracy: 0.9442\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.9482\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.9323\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9522\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9801\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.9761\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9641\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9761\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9721\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0712 - accuracy: 0.9880\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9801\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0637 - accuracy: 0.9761\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9801\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9880\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9801\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9960\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9920\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0465 - accuracy: 0.9880\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9960\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9920\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9960\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0120 - accuracy: 0.9960\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9960\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9880\n",
      "accuracy: 0.8939393939393939\n",
      "precision: 0.8967801167289657\n",
      "recall: 0.8910256410256411\n",
      "f1: 0.8905542393914487\n",
      "confusion matrix\n",
      "[[24  2  0]\n",
      " [ 0 19  1]\n",
      " [ 2  2 16]]\n"
     ]
    }
   ],
   "source": [
    "predict_for_PCA(X_train_PCA,y_train,X_test_PCA,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "indian-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "df_zca = pd.read_csv('zca_500.csv')\n",
    "df_test_zca = pd.read_csv('zca_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "million-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_zca = df_zca.iloc[: , 1:-1]\n",
    "X_train_zca = X_train_zca/255\n",
    "y_train_zca = df_zca.iloc[: , -1:].values.ravel()\n",
    "\n",
    "X_test_zca = df_test_zca.iloc[: , 1:-1]\n",
    "X_test_zca = X_test_zca/255\n",
    "y_test_zca = df_test_zca.iloc[: , -1:].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "played-henry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455, 3)\n",
      "(66, 3)\n"
     ]
    }
   ],
   "source": [
    "y_train_zca = to_categorical(label_encoder.fit_transform(y_train_zca),3)\n",
    "y_test_zca = to_categorical(label_encoder.fit_transform(y_test_zca),3)\n",
    "print(y_train_zca.shape)\n",
    "print(y_test_zca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "activated-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_zca(optimizer):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,input_dim=X_train_zca.shape[1],kernel_initializer=\"uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32,kernel_initializer=\"uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(16,kernel_initializer=\"uniform\"))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "def predict_ZCA(x,y,test_x,test_y):\n",
    "    model = KerasClassifier(build_fn=create_model_zca, verbose=0)\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x,y, test_size=0.25, random_state=1) # 0.25 \n",
    "    #利用grid search調參數\n",
    "    batch_size = [32,128]\n",
    "    opt = ['rmsprop','adam']\n",
    "    param_grid = dict(optimizer=opt,batch_size=batch_size)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=10)\n",
    "    grid_result = grid.fit(X_train, y_train,validation_data=(X_val,y_val),callbacks=[callback])\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    optimizer_best = grid_result.best_params_['optimizer']\n",
    "    batch_best = grid_result.best_params_['batch_size']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    model_best =  Sequential()\n",
    "    model_best.add(Dense(64,input_dim=x.shape[1],kernel_initializer=\"uniform\"))\n",
    "    model_best.add(Activation('relu'))\n",
    "    model_best.add(Dropout(0.4))\n",
    "    model_best.add(Dense(32,kernel_initializer=\"uniform\"))\n",
    "    model_best.add(Activation('relu'))\n",
    "    model_best.add(Dropout(0.4))\n",
    "    model_best.add(Dense(16,kernel_initializer=\"uniform\"))\n",
    "    model_best.add(Activation('relu'))\n",
    "    model_best.add(Dropout(0.4))\n",
    "    model_best.add(Dense(3))\n",
    "    model_best.add(Activation('softmax'))\n",
    "    model_best.compile(optimizer=optimizer_best, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    history = model_best.fit(X_train, y_train,validation_data=(X_val,y_val),batch_size=batch_best,epochs=30,callbacks=[callback])\n",
    "    Y_pred = model_best.predict_generator(test_x)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    y_test_argmax = np.argmax(test_y, axis=1)\n",
    "    accuracy = accuracy_score(y_test_argmax, y_pred)\n",
    "    print('accuracy:', accuracy)\n",
    "    precision = precision_score(y_test_argmax, y_pred, average = 'macro')\n",
    "    print('precision:', precision)\n",
    "    recall = recall_score(y_test_argmax, y_pred, average = 'macro')\n",
    "    print('recall:', recall)\n",
    "    f1 = f1_score(y_test_argmax, y_pred, average = 'macro')\n",
    "    print('f1:',f1)\n",
    "    cm = confusion_matrix(y_test_argmax, y_pred)\n",
    "    print('confusion matrix')\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "parliamentary-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 21 calls to <function Model.make_test_function.<locals>.test_function at 0x7f926da465e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f926da465e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92385a9b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92385a9b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9248f77040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9248f77040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f926157c3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f926157c3a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9248ca9940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9248ca9940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9264f69dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9264f69dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9289bb1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9289bb1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92af9aef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92af9aef70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f929c640ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f929c640ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92a9d1d9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92a9d1d9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92a95bb5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92a95bb5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92af182670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92af182670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92cae51040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92cae51040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92cba6ed30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f92cba6ed30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f927d7a63a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f927d7a63a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9259f165e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9259f165e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f923d300ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f923d300ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f923d639dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f923d639dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f924bb11f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f924bb11f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9238513700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Best: 0.348324 using {'batch_size': 128, 'optimizer': 'rmsprop'}\n",
      "0.328123 (0.039587) with: {'batch_size': 32, 'optimizer': 'rmsprop'}\n",
      "0.325413 (0.066416) with: {'batch_size': 32, 'optimizer': 'adam'}\n",
      "0.348324 (0.057835) with: {'batch_size': 128, 'optimizer': 'rmsprop'}\n",
      "0.305229 (0.030753) with: {'batch_size': 128, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.1051 - accuracy: 0.3364WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f9243f25af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 1.1051 - accuracy: 0.3364 - val_loss: 1.0971 - val_accuracy: 0.3434\n",
      "Epoch 2/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0985 - accuracy: 0.3501 - val_loss: 1.0970 - val_accuracy: 0.3434\n",
      "Epoch 3/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1029 - accuracy: 0.3199 - val_loss: 1.0970 - val_accuracy: 0.3434\n",
      "Epoch 4/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0997 - accuracy: 0.3162 - val_loss: 1.0982 - val_accuracy: 0.3159\n",
      "Epoch 5/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0987 - accuracy: 0.3346 - val_loss: 1.0969 - val_accuracy: 0.3434\n",
      "Epoch 6/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.1008 - accuracy: 0.3226 - val_loss: 1.0971 - val_accuracy: 0.3434\n",
      "Epoch 7/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0987 - accuracy: 0.3162 - val_loss: 1.0971 - val_accuracy: 0.3434\n",
      "Epoch 8/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0988 - accuracy: 0.3226 - val_loss: 1.0986 - val_accuracy: 0.3159\n",
      "Epoch 9/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0983 - accuracy: 0.3236 - val_loss: 1.0976 - val_accuracy: 0.3709\n",
      "Epoch 10/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0981 - accuracy: 0.3245 - val_loss: 1.0968 - val_accuracy: 0.3626\n",
      "Epoch 11/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0989 - accuracy: 0.3236 - val_loss: 1.0971 - val_accuracy: 0.3709\n",
      "Epoch 12/30\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0969 - accuracy: 0.3538 - val_loss: 1.0962 - val_accuracy: 0.3626\n",
      "Epoch 13/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0973 - accuracy: 0.3364 - val_loss: 1.0975 - val_accuracy: 0.3159\n",
      "Epoch 14/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0977 - accuracy: 0.3456 - val_loss: 1.0962 - val_accuracy: 0.3654\n",
      "Epoch 15/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0981 - accuracy: 0.3474 - val_loss: 1.0965 - val_accuracy: 0.3462\n",
      "Epoch 16/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0979 - accuracy: 0.3254 - val_loss: 1.0977 - val_accuracy: 0.3159\n",
      "Epoch 17/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0969 - accuracy: 0.3501 - val_loss: 1.0954 - val_accuracy: 0.3654\n",
      "Epoch 18/30\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 1.0958 - accuracy: 0.3391 - val_loss: 1.0954 - val_accuracy: 0.3187\n",
      "Epoch 19/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0948 - accuracy: 0.3217 - val_loss: 1.0955 - val_accuracy: 0.3159\n",
      "Epoch 20/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0964 - accuracy: 0.3428 - val_loss: 1.0957 - val_accuracy: 0.3159\n",
      "Epoch 21/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0964 - accuracy: 0.3474 - val_loss: 1.0967 - val_accuracy: 0.3654\n",
      "Epoch 22/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0971 - accuracy: 0.3401 - val_loss: 1.0965 - val_accuracy: 0.3791\n",
      "Epoch 23/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0960 - accuracy: 0.3364 - val_loss: 1.0963 - val_accuracy: 0.3819\n",
      "Epoch 24/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0932 - accuracy: 0.3529 - val_loss: 1.0920 - val_accuracy: 0.3709\n",
      "Epoch 25/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0938 - accuracy: 0.3456 - val_loss: 1.0958 - val_accuracy: 0.5055\n",
      "Epoch 26/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0958 - accuracy: 0.3373 - val_loss: 1.0959 - val_accuracy: 0.4368\n",
      "Epoch 27/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0951 - accuracy: 0.3520 - val_loss: 1.0903 - val_accuracy: 0.3626\n",
      "Epoch 28/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0932 - accuracy: 0.3538 - val_loss: 1.0987 - val_accuracy: 0.3407\n",
      "Epoch 29/30\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0919 - accuracy: 0.3410 - val_loss: 1.0990 - val_accuracy: 0.3407\n",
      "Epoch 30/30\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 1.0913 - accuracy: 0.3740 - val_loss: 1.0852 - val_accuracy: 0.3736\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f923ee85430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "accuracy: 0.3484848484848485\n",
      "precision: 0.26060606060606056\n",
      "recall: 0.36410256410256414\n",
      "f1: 0.25009009009009003\n",
      "confusion matrix\n",
      "[[ 5  0 21]\n",
      " [ 4  0 16]\n",
      " [ 2  0 18]]\n"
     ]
    }
   ],
   "source": [
    "predict_ZCA(X_train_zca,y_train_zca,X_test_zca,y_test_zca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "white-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_500 = pd.read_csv('train_DG_500.csv')\n",
    "X_train_500 = df_500.iloc[: , 1:-1]\n",
    "X_train_500 = X_train_500/255\n",
    "y_train_500 = df_500.iloc[: , -1:].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "grand-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_500 = to_categorical(label_encoder.fit_transform(y_train_500),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ahead-complexity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.951090 using {'batch_size': 128, 'epochs': 30, 'optimizer': 'adam'}\n",
      "0.951082 (0.015140) with: {'batch_size': 32, 'epochs': 30, 'optimizer': 'adam'}\n",
      "0.951090 (0.027647) with: {'batch_size': 128, 'epochs': 30, 'optimizer': 'adam'}\n",
      "Epoch 1/30\n",
      "12/12 [==============================] - 4s 297ms/step - loss: 1.0819 - accuracy: 0.4580\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.8860 - accuracy: 0.6327\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.5935 - accuracy: 0.7533\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 2s 127ms/step - loss: 0.4785 - accuracy: 0.8133\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 2s 162ms/step - loss: 0.3936 - accuracy: 0.8553\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 0.3425 - accuracy: 0.8767\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 0.3102 - accuracy: 0.8887\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.2986 - accuracy: 0.8960\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.2721 - accuracy: 0.9093\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 0.2545 - accuracy: 0.9127\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 2s 168ms/step - loss: 0.2367 - accuracy: 0.9180\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.2212 - accuracy: 0.9307\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 0.2115 - accuracy: 0.9313\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 0.2008 - accuracy: 0.9347\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 2s 131ms/step - loss: 0.1928 - accuracy: 0.9373\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 2s 133ms/step - loss: 0.1802 - accuracy: 0.9413\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 1s 120ms/step - loss: 0.1680 - accuracy: 0.9447\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 2s 129ms/step - loss: 0.1895 - accuracy: 0.9380\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 2s 171ms/step - loss: 0.1577 - accuracy: 0.9513\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 4s 331ms/step - loss: 0.1778 - accuracy: 0.9387\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 4s 324ms/step - loss: 0.1415 - accuracy: 0.9580\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 4s 303ms/step - loss: 0.1317 - accuracy: 0.9547\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 0.1166 - accuracy: 0.9607\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 1s 106ms/step - loss: 0.1173 - accuracy: 0.9607\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.1141 - accuracy: 0.9667\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 2s 158ms/step - loss: 0.1093 - accuracy: 0.9660\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 0.0979 - accuracy: 0.9700\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.0926 - accuracy: 0.9680\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 0.0985 - accuracy: 0.9700\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 0.0888 - accuracy: 0.9760\n",
      "WARNING:tensorflow:From <ipython-input-26-48f5a1a00367>:36: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "accuracy: 0.8333333333333334\n",
      "precision: 0.8339542483660131\n",
      "recall: 0.8282051282051283\n",
      "f1: 0.8255855855855855\n",
      "confusion matrix\n",
      "[[23  2  1]\n",
      " [ 0 14  6]\n",
      " [ 1  1 18]]\n"
     ]
    }
   ],
   "source": [
    "predict(X_train_500,y_train_500,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "restricted-excuse",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 1.0478 - accuracy: 0.4444 - val_loss: 0.8320 - val_accuracy: 0.6453\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.7200 - accuracy: 0.6764 - val_loss: 0.5127 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 5s 133ms/step - loss: 0.5664 - accuracy: 0.7467 - val_loss: 0.4262 - val_accuracy: 0.8320\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 5s 133ms/step - loss: 0.4800 - accuracy: 0.8080 - val_loss: 0.4019 - val_accuracy: 0.8533\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.3875 - accuracy: 0.8560 - val_loss: 0.3202 - val_accuracy: 0.8773\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 5s 125ms/step - loss: 0.3880 - accuracy: 0.8453 - val_loss: 0.2829 - val_accuracy: 0.8933\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 4s 121ms/step - loss: 0.3412 - accuracy: 0.8747 - val_loss: 0.2865 - val_accuracy: 0.9040\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 0.3254 - accuracy: 0.8836 - val_loss: 0.2914 - val_accuracy: 0.8880\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 5s 128ms/step - loss: 0.3044 - accuracy: 0.8916 - val_loss: 0.2415 - val_accuracy: 0.9120\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 0.3052 - accuracy: 0.8987 - val_loss: 0.2232 - val_accuracy: 0.9227\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.2745 - accuracy: 0.9093 - val_loss: 0.2356 - val_accuracy: 0.9067\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.2569 - accuracy: 0.9173 - val_loss: 0.2464 - val_accuracy: 0.9120\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.2800 - accuracy: 0.9022 - val_loss: 0.2206 - val_accuracy: 0.9227\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.2359 - accuracy: 0.9271 - val_loss: 0.2508 - val_accuracy: 0.9173\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.2334 - accuracy: 0.9200 - val_loss: 0.1942 - val_accuracy: 0.9307\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.2303 - accuracy: 0.9244 - val_loss: 0.2767 - val_accuracy: 0.9093\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.2330 - accuracy: 0.9218 - val_loss: 0.3248 - val_accuracy: 0.8853\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.2474 - accuracy: 0.9076 - val_loss: 0.2144 - val_accuracy: 0.9280\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.2118 - accuracy: 0.9324 - val_loss: 0.1765 - val_accuracy: 0.9360\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.2083 - accuracy: 0.9431 - val_loss: 0.1804 - val_accuracy: 0.9333\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb2e87703a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "accuracy: 0.8333333333333334\n",
      "precision: 0.8383333333333333\n",
      "recall: 0.8282051282051283\n",
      "f1: 0.8265795206971678\n",
      "confusion matrix\n",
      "[[23  2  1]\n",
      " [ 0 14  6]\n",
      " [ 2  0 18]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_500,y_train_500, test_size=0.25, random_state=1) # 0.25 \n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "model_best =  Sequential()\n",
    "model_best.add(Dense(256,input_dim=X_train_500.shape[1],kernel_initializer=\"uniform\"))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.5))\n",
    "model_best.add(Dense(128,kernel_initializer=\"uniform\"))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.5))\n",
    "model_best.add(Dense(64,kernel_initializer=\"uniform\"))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.5))\n",
    "model_best.add(Dense(3))\n",
    "model_best.add(Activation('softmax'))\n",
    "model_best.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "history = model_best.fit(X_train, y_train,validation_data=(X_val,y_val),batch_size=32,epochs=20,callbacks=[callback])\n",
    "Y_pred = model_best.predict_generator(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_test_argmax = np.argmax(y_test, axis=1)\n",
    "accuracy = accuracy_score(y_test_argmax, y_pred)\n",
    "print('accuracy:', accuracy)\n",
    "precision = precision_score(y_test_argmax, y_pred, average = 'macro')\n",
    "print('precision:', precision)\n",
    "recall = recall_score(y_test_argmax, y_pred, average = 'macro')\n",
    "print('recall:', recall)\n",
    "f1 = f1_score(y_test_argmax, y_pred, average = 'macro')\n",
    "print('f1:',f1)\n",
    "cm = confusion_matrix(y_test_argmax, y_pred)\n",
    "print('confusion matrix')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-soldier",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
